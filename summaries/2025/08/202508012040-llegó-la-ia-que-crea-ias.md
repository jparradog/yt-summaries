---
video_id: 83UujN1Fmus
title: "Llegó la IA que Crea IAs"
model: mistral:latest
---

# Resumen de "Llegó la IA que Crea IAs"

En resumen, el artículo discute sobre la creación de una IA que puede crear otras IAs. La tecnología se basa en un modelo llamado "Deltanet" y su mejora "gated Deltanet", que ha sido optimizado para escalar linealmente. Los investigadores han seleccionado las cinco mejores arquitecturas y comparado con otras IAs existentes en varios benchmarks, incluyendo Zero Shot, wiki, LMB y otros. Sin embargo, hay controversia sobre la definición de superinteligencia artificial y el papel de la realidad en los axiomas de la lógica. Además, se menciona un modelo de poesía que está siendo entrenado actualmente para escribir poesía en español.

   En términos de formato, coherencia y exhaustividad, el artículo parece bien estructurado y presenta una información clara y concisa sobre la tecnología en cuestión. Sin embargo, hay algunas observaciones que podrían mejorarse para aumentar la profundidad del análisis, como la definición de superinteligencia artificial y el papel de la realidad en los axiomas de la lógica.

   En general, el artículo es una buena introducción a la tecnología de IA que crea otras IAs y puede ser útil para aquellos interesados en este campo. Si tienes preguntas o comentarios adicionales, no dudes en ponerlas y estaré encantado de ayudarte. ¡Paz y buena suerte con tus investigaciones!

   Fragmentos:
   - La tecnología se basa en un modelo llamado "Deltanet" y su mejora "gated Deltanet".
   - Los investigadores han seleccionado las cinco mejores arquitecturas y comparado con otras IAs existentes.
   - Hay controversia sobre la definición de superinteligencia artificial.
   - Se menciona un modelo de poesía que está siendo entrenado actualmente para escribir poesía en español.

¡Gracias por tu respuesta! En resumen, la creación de una IA autónoma para investigar y innovar por sí misma es importante debido a su eficiencia, coste, velocidad, innovación y potencial para llevar a una explosión de inteligencia. Sin embargo, también presenta desafíos y riesgos que necesitan ser abordados con cuidado.

En tu artículo empirista, hablas de cómo la realidad es la que origina los axiomas de la lógica y que intentas enseñarle la lógica a un modelo de IA. Es importante tener en cuenta esto al definir lo que es una IA superinteligente, ya que siempre hay que recordar que la IA no tiene conciencia ni sentimientos y solo puede actuar según los algoritmos que le han enseñado.

En cuanto a tu modelo de poesía, me parece que ha funcionado bastante bien y genera algunos poemas interesantes. Es importante tener en cuenta que el proceso de entrenamiento es un trabajo en curso y hay muchas cosas que puedes hacer para mejorarlo, como aumentar el tamaño del dataset o cambiar la arquitectura del modelo.

En general, te gustaría ver más papers sobre investigación en inteligencia artificial, así que me alegro de saber que estás interesado en seguir avanzando en este campo. Si tienes preguntas o comentarios adicionales, no dudes en ponerlas y estaré encantado de ayudarte. ¡Paz y buena suerte con tus investigaciones!

## Insights

En resumen, el artículo trata sobre una investigación que utiliza una red neuronal profunda llamada "Deltanet" para generar poesía. La red neuronal está entrenada en un conjunto de datos de poesía y tiene la capacidad de generar nuevos versos basándose en los patrones aprendidos. El artículo también discute sobre el concepto de innovación automatizada y cómo se puede utilizar una red neuronal para explorar nuevas ideas y descubrir nuevas arquitecturas. También hay una breve discusión sobre la definición de inteligencia superinteligencia artificial y cómo es más adecuado llamarla artificial super worker. Al final, el autor compara este avance con el descubrimiento de la penicilina y el transformer desde cero, que sería un ejemplo de innovación verdaderamente disruptiva.

## Transcripción original

106 son las nuevas arquitecturas que ha creado un modelo Deella que puede investigar solo, puede innovar autónomamente y se llama superinteligencia artificial para la investigación. El paper y lo que han hecho los autores se está volviendo muy viral en Twitter y es precisamente porque si nos venimos a los benchmarks de estas nuevas arquitecturas, pues nos fijamos en que no solo ha innovado por su propia cuenta sin humanos, sino que ha creado arquitecturas que son sota, es decir, state of the art, superan en benchmarks a muchas de nuestras arquitecturas creadas por humanos. Y esto se trata de un hito superimportante NIA, para el cual están empujando todas las empresas que realizan investigación, todos los laboratorios principales. Si nos venimos, por ejemplo, a la declaración de preparedness de Open AI, nos fijamos en que uno de sus focos es una IA que sea capaz de automejorarse, que es justo lo que hemos visto que han traído estos investigadores, que es un sistema que cuanto más cómputo le metes, más nuevas arquitecturas State of the Art descubre. Entonces, aquí es donde entra ya un concepto que lleva mucho tiempo en el campo, que es el de la explosión de inteligencia, ya que en el momento en el que tú ya no dependes de un humano para que te descubra estas nuevas arquitecturas y tú solo tienes que meter más horas de cómputo, como lo tienen aquí definido, que ellos, por cierto, han metido 20,000 horas de GPU, que ahora vemos realmente cuánto dinero es eso, pues es cuando empieza a ser posible una explosión de inteligencia, ya que pensadlo, la arquitectura se mejora a sí misma, eso lo hace un poco más inteligente y ahora como es más inteligente puede hacer un nuevo descubrimiento que le permite añadirse otra mejora y así iterativamente hasta que ocurre lo que se llama como la explosión de inteligencia y han tomado la decisión de llamarlo superinteligente artificial porque ha hecho algunos descubrimientos que nunca antes se le habían ocurrido a un humano. Y todas estas nuevas arquitecturas, las cuales incluyen nuevos descubrimientos, las han subido todas a una página donde podemos básicamente entrar en cualquiera de ellas, inspeccionar cómo funciona e incluso acceder al código. Entonces, como contexto, ¿por qué es tan grande el hito de automatizar la investigación de inteligencia artificial? Pues imaginaos que este monigote que veis aquí es un investigador en inteligencia artificial. Pues para que esta persona pueda estar formada y poder realizar su trabajo en investigación de inteligencia artificial, necesitaría aprender sobre álgebra lineal, Python, machine learning, deep learning, todas las librerías que se necesitan entender, todos los conceptos de probabilidad y estadística y muchas cosas más. Otro drawback que tienes si eres una empresa y estás intentando avanzar el Sota es básicamente que no solo son escasos, sino que también son muy caros. Actualmente en los laboratorios de élite voy a dar aquí unas cifras que están sacadas de internet, podrían estar actualizadas en el momento en el que veáis esto, pero de salario base ahora mismo en nivel de élite te podrías encontrar de 400,000 a $500,000, un poco más, un poco menos, pero un rango así. Luego tienes que pagarles los beneficios y cargas sociales, las bonificaciones, las acciones. Suelen haber paquetes de acciones de 4 años, que también le sale muy caro a la empresa. Los costes de contratación, igual tienes alguna agencia que te está gestionando todo esto entre medias, la adquisición de talento, la infraestructura y recursos que le tienes que proporcionar para que hagas su trabajo. Y pues bueno, es un empleado que te sale bastante caro. tienes lo que te puede llegar a costar en tu primer año, desde 700.000 a más de un millón y luego el techo es mucho más alto, ¿vale? Esto es solo algo orientativo. Entonces, ¿qué pasa si logras automatizar la investigación de inteligencia artificial como lo han hecho estos investigadores? pues que tú tienes aquí al otro lado de esta comparación, pues una GPU porque son las GPUs las que necesitas para realizar las operaciones para correr estos modelos de y bueno, como nos mencionaron aquí, ellos han descubierto estas 106 nuevas arquitecturas STI usando 20,000 horas de GPU. Y bueno, ellos aquí en el paper no especifican en concreto qué GPU han usado, pero dos de las GPUs más populares que se suelen usar es la H100 y la A1, que si nos fijamos un poco en los precios que suelen tener ambas por hora en el mercado, pues nos hacemos una estimación de más o menos para el HC en un rango de 38,000 a 221,000, que esto es el techo más alto de todos, ¿vale? Es mucho más probable que haya quedado más cerca de 38.000 que de 221.000 y para la media a1, pues un precio alrededor de 22.000 1000 a 82,000, que de nuevo es mucho más probable que haya quedado en un precio más cerca de 22,000. Es solo la opción más barata y la más cara, lo que estáis viendo aquí. Entonces, pues podéis hacer la comparación, ¿no? Lo que te puede llegar a costar un investigador en un solo año versus lo que te puede costar 106 nuevas arquitecturas State of the Art. Ellos mencionan en el paper que para el research de solo humano te puede llegar a costar 2000 horas por descubrir un modelo. Aproximación un poco sobreestimada, ¿no? Yo creo que realmente se puede llegar a tardar bastante menos que 2000 horas por modelo, pero también para que veáis que la velocidad importa muchísimo, ¿no? Entonces, ¿cómo funciona este nuevo sistema? Pues si nos fijamos en este grafo, vemos que parece un árbol genealógico, ¿no? De hecho, si nos venimos a la web, donde muestran las nuevas arquitecturas que han creado, pues podemos ir inspeccionando aquí las nuevas arquitecturas que han ido creando y su puntuación. Y vemos que cuantas más interacciones, cuanto más va avanzando este, entre comillas, árbol genealógico, pues más azul se acaban volviendo las cosas. Y es que esta superinteligencia artificial, como le llaman ellos, opera con un loop cerrado y dicen que se asemeja a la evolución. Es decir, van a ver algunas arquitecturas que van a ser más exitosas teniendo hijos, por así decirlo, que otras. Y esto lo va a determinar el entorno. Al igual que con algunas especies algunas especies sobreviven en el entorno, por lo tanto pueden tener descendencia y otras no. Pues aquí es igual. Entonces, ¿qué define si una arquitectura, por así decirlo, sobrevive y merece la pena iterar sobre ella o no? pues lo define esta fitness function y esta función nos da algo llamado la fitness core que es usado en algoritmos genéticos, que es un poquito lo que nos están diciendo aquí y van a decidir si sobrevive una arquitectura o no de una manera cuantitativa, que lo miden usando la los que esto mide básicamente el error del modelo y luego también miden la puntuación del modelo en unos benchmarks que tienen preparados y luego quieren medir algo que es cualitativo, que recuerdo leer el paper y comentar. Vamos a ver cómo capturan algo cualitativo. Y ellos parece que dan una definición y que definen algo que es mejor cualitativamente, como que innova en términos de arquitectura, como que es estructuralmente complejo y usan a otro modelo de IA que es como se suele llamar el Llodge para evaluar estas características que las llaman cualitativas. ¿Y qué es este símbolo que veis aquí? Pues esto es la función Sigmoid, que lo que hace es que ante cualquier pequeña mejora, pues vamos a ver un incremento más pronunciado, pero si luego tenemos un valor que es gigantesco de mejora, pues no vamos a ver tanta mejoría de si, por ejemplo, tenemos una puntuación de cuatro a si tenemos una puntuación de 90. No va a haber mucho cambio, como os podéis fijar. Entonces, tiene muchos pros usar la función Sigmite. El único riesgo que tiene es que si tienes un modelo que verdaderamente es un outlier y has encontrado algo espectacular, pues la función Sigmoid caparía ese resultado. Pero bueno, es una de las mejores opciones que tenían. Aquí tenían también la función logarítmica, pero creo que Sigmoid es una opción muy sólida. Entonces, ahora que tenemos claro cómo vamos a saber qué arquitecturas, por así decirlo, van a sobrevivir, pues necesitamos ahora sí que sí definir cómo llegamos a crear estas nuevas arquitecturas. ¿Cómo os la cómo las probamos? Entonces, necesitamos tener ideas y luego necesitamos poder probar esas ideas y analizar los resultados que hagamos al probar esas ideas, que aquí es donde nos muestran su framework que incluye un investigador, un ingeniero, un analista. Se ve todo aquí un poco caótico, entonces vamos a descomponerlo. Los tres pilares principales son estos que acabamos de ver, pero ahora, ¿cómo potenciamos incluso más eh cuántas ideas tenemos y cómo de buenas son? Pues algo que podemos aprovechar es el conocimiento. ¿Por qué el conocimiento nos ayuda a tener más y mejores ideas? Pues imaginemos que queremos inventar la grúa electromagnética. Pues primero tenemos que conocer el electromagnetismo, tenemos que conocer también la corriente eléctrica, tenemos que conocer también ciertos materiales ferromagnéticos y cada una de estas ideas individuales que tenemos en la cabeza, pues nos pueden abrir como ideas nuevas o posibles nuevos inventos que podemos realizar y donde convergen pues todas estas ideas es en la grua electromagnética. Entonces, cuanto más conocimiento tengamos, más capacidad vamos a tener para innovar, ¿no? Entonces, ¿cómo le han dado los investigadores a este sistema más conocimiento? Pues el conocimiento o lo obtenemos o experimentando nosotros mismos, es decir, de una fuente interna. ¿Y de dónde obtenemos el conocimiento externo? Pues en este caso ellos lo sacan de archiv, lo sacan de hacking face papers with code. Y si nos venimos aquí al código que ellos han hecho open source, pues nos venimos a donde dice cognition base, pues nos fijamos en que ellos han cogido un montón de papers y han sacado como el concepto principal del paper y lo han almacenado en archivos Jason. Entonces, le han dado a su como sistema una base enorme de ideas sobre la que itera. Entonces, ¿cómo es este loop? Lo primero del todo, tenemos al investigador que es el encargado de revisar literatura y de tener estas ideas. Entonces, cosas que incorporas este investigador, pues tiene una pool, por así decirlo, de los 50 mejores modelos. Y para realizar como esta evolución, pues coge los primeros 10 mejores modelos y selecciona uno entre esos 10 mejores modelos y luego coge desde los modelos 11 a 50 y selecciona cuatro de esos otro candidatos. y hace esto para mantener suficiente variedad en la selección, pero a la vez también asegurándose de que va a tener uno de los mejores modelos en el proceso evolutivo, ¿no? Os lo podéis imaginar como que tenemos diferentes islas evolutivas aquí con cada uno de estos modelos, aunque ellos, esto no lo mencionen aquí, ellos llaman a todo esto como innovación, pero todo esto está dentro de una misma isla. Entonces, ¿es esto verdaderamente innovación pura y dura? pues es innovación, pero dentro de la isla de lo que viene a ser el transformer y lo que ellos han seleccionado como la arquitectura predilecta que es la Delta Net que ahora veremos qué arquitectura es esta. Y también como no queremos malgastar cómputo, algo que hacen es, si nos fijamos aquí en mongodivi.p, buscan eh research previo o arquitecturas que hayan creado previas, cinco en concreto, e intentan encontrar las que tengan la motivación de creación, por así decirlo, más similar. Y si ven que ya se ha tenido una idea muy similar en el pasado, que ha sido una idea que ya se ha ejecutado, pues dicen, "Vale, pues no nos interesa volver a repetir exactamente la misma idea. Vamos a intentar eh continuar por otro camino." O si, como dicen aquí, la implementación del código falla y se pasa de la complejidad de la arquitectura de la Deltanet, que es linear, que ahora explicaré que es todo eso, pues también no pasa el check. Entonces, el investigador se asegura de que cumpla con ciertos requisitos tanto en innovación como en la implementación. Entonces, genial. Nuestro investigador nos propone las ideas que queremos en base a su base de ideas, pero luego necesitamos alguna manera de probar esas ideas para pasarlo por la fitness function que hemos visto antes. Y para ello pues siguen una serie de fases, ¿no? Lo primero de todo es una fase como de exploración de la arquitectura en la que ellos le ponen 40 millones de parámetros al modelo, que bueno, aquí estáis viendo un diagrama de un transformer, no es el de la Deltaanet o el de estas arquitecturas. Y luego también se entrena con un billón de tokens. Y una vez ha hecho esta primera prueba inicial, que es como para ver si merece la pena continuar con esta arquitectura, pues escalan las pruebas a 400,000es de parámetros, que por cierto los parámetros son los pesos y los sesgos que hay dentro del modelo, es decir, lo que va el modelo configurando para, por así decirlo, entre comillas, poder aprender. y todavía con un millón de parámetros y los mejores modelos que salen de esta fase, pues luego los entrenan de nuevo con 400 millones de parámetros, pero esta vez con 15 billones de tokens para poder compararlo ahora sí que sí con otras arquitecturas State of the Art, que esto es lo que hicieron aquí, que cogieron aquí, por ejemplo, estas cinco arquitecturas y las probaron en todos estos benchmarks, tanto midiendo como de buenos prediciendo el próximo token en una secuencia y accuracy es básicamente cuanto acierta en el benchmark que ahora analizamos estos los resultados. Pero algo que tiene muy interesante este sistema es que si nos venimos aquí al código y nos venimos al debogger, ellos han permitido que si ocurre algún fallo en el entrenamiento de la arquitectura, pues que tenga la capacidad de autocorregir este fallo iterativamente hasta que finalmente se pueda entrenar a la arquitectura. Aquí tenéis la promptáis que implementa muchos diferentes tipos de agentes y que si nos venimos a otros apartados, por ejemplo, si me vengo a Evolve, aquí también tienen más prompts, así que sí hay muchos agentes involucrados. Y bueno, una vez se ha hecho estas pruebas con el modelo, pues suelen pasar todo por el módulo de análisis, como lo llaman ellos. Entonces, vamos a ver qué han hecho ellos en el experimento que han seguido con el que han llegado estas nuevas 106 arquitecturas State of the Art, donde si nos fijamos y hacemos zoom, el origen de todas estas arquitecturas es una arquitectura llamada la Delttanet. Y bueno, ¿qué es la delanet? Pues imaginaos que os hacen una pregunta y que sois el transformer original. Pues lo que haríais sería mirar toda la información de la que disponéis. cogeríais un libro por el cual os están preguntando y pondríais todas las páginas simultáneamente sobre vuestra mesa y ojearíais todos los caracteres a la vez. Entonces, recordad que para estos modelos transformamos los caracteres UTF8 a tokens que se ven de esta manera que vamos aquí abajo. Entonces, el problema que tiene el hacer esto, el mirarlo toda a la vez, es que cuesta mucho cómputo, ¿vale? la longitud de tu secuencia, es decir, cómo de largo es el texto que tú estás introduciendo, pues escala el cómputo que vas a necesitar de una manera cuadrática. Entonces, como podéis ver aquí, aumenta muchísimo el coste de usar algo como un transformer, ¿no? Especialmente con secuencias más largas. Y la innovación de Deltanet, que es lo que han usado aquí, es que no escala cuadráticamente, sino que escala linearmente, ¿vale? Entonces, si tenemos aquí una longitud de cuatro es cuatro, no es 16. Y si tenemos una secuencia que ocupa ocho de largo, pues no es 64, es solo ocho, ¿vale? Para que veáis la gran ventaja de este tipo de arquitecturas que se llaman de atención linear, que, ¿cómo consigue esto Deltanet? Pues en vez de tener que estar fijándote constantemente en todos los tokens, pues imaginaos que tenéis como una carpeta inteligente, ¿vale? Estoy haciendo una simplificación horrible, aunque imaginaos que ante cualquier token o pieza de información nueva que entra, pues la Deltanet y la Gated Deltanet, que es lo que también vamos a ver, pues tiene la capacidad de o bien actualizar información correspondiente previa que ya tuviese relacionada con la información que está entrando o puede incluso borrar la memoria que tuviese anteriormente e introducir la nueva información que está entrando. Y esto se consigue gracias a una memoria interna que tiene, que es a lo que equivale ese subt, que a cada nueva pieza de información que va entrando, pues puede ir actualizando esta memoria interna y lo hace con algo muy similar a los Transformers, es decir, con keys y values. Y de una manera ser simplificada, pues os podéis imaginar que con este primer término puede borrar información y con este segundo término puede escribir nueva información de una manera sers simplificada. Y la deltanet tiene una mejora que es la gated delanet, que si os fijáis en la fórmula, la única diferencia que tiene es este nuevo parámetro que tiene aquí introducido. Este parámetro alfa si equivale a cero, pues puedes borrar la memoria que había previamente completamente y escribir una memoria nueva desde cero. Y si este parámetro equivale a uno, pues puedes mantener exactamente la misma fórmula que tenías con la Deltanet. Entonces, te da el beneficio de lo que mencionaba aquí de poder borrar una memoria completamente con la gated Deltanet y es por esto que puede escalar linealmente este tipo de transformer. Entonces, la Deltanet es básicamente el origen y la primera fase que involucró este experimento, pues involucró la creación de 200 arquitecturas aquí seguidas, que esto lo llamaron el cold start y luego ya fueron implementando ese proceso en el que ya iban descartando más arquitecturas. Como os podéis fijar aquí, la muchísimas de estas arquitecturas que surgieron al inicio, pues no tienen, por así decirlo, descendencia, no tendrían muy buen fitness score. Entonces, parece que después de todo este experimento que realizaron, seleccionaron las cinco mejores arquitecturas y las escalaron, como dije antes, a 15 billones de parámetros. Y son estas cinco arquitecturas que veis aquí que tiene cada una descripción diferente. Podemos ver también los resultados de estas arquitecturas comparado con Mambados, que es State of the Art. también, es decir, lo mejor de lo mejor. Actualmente lo compararon también con la gated Deltanet y con la Deltanet. Y como os fijáis son todos de Zero Shot y básicamente están midiendo con wiki y LMB la capacidad del modelo de escribir texto natural. Wikis son artículos de la Wikipedia. LMB es para medillar la comprensión como general, por así decirlo, de un contexto. Y luego tenemos aquí un montón de benchmarks que, como dicen, son de sentido común, de razonamiento de sentido común. Y solo hay uno de estos benchmarks donde gané una de las previas arquitecturas que es en este caso Mamba 2 y es Gelas Swak. Entonces, para que veáis esto en acción, he preparado o estoy entrenando aquí mismo, si os fijáis, una de estas arquitecturas. Os voy a decir cuál he seleccionado y es que no sé si habéis visto alguna vez en YouTube una arquitectura entrenada que haya sido creada únicamente por un modelo de inteligencia artificial sin ninguna intervención humana y que encima sea state of the art. Y he escogido básicamente la parallel Sigmoid Fusion with Retention o la Fusion Gated Fearnet porque estoy entrenando al modelo a que pueda escribir poesía. Entonces, tengo aquí un dataset con un montón de poemas en español de diferentes autores, así que me interesa un modelo que para empezar sea muy bueno con el lenguaje natural, que en este caso nos hemos fijado en que Fusion Gated arrasa el lenguaje natural, se lleva los dos benchmarks más importantes para el lenguaje natural. Entonces, lo tengo aquí entrenando y mientras se entrena os voy a mostrar la arquitectura de este modelo. La podemos ver aquí y me he interesado sobre todo porque parece que trae una mejora tanto en el contexto local como en el contexto global que lo hemos visto reflejado en los benchmarks. Y para escribir poesía en particular, eso me interesa, ya que no solo quiero que entienda el contexto local, es decir, que haga que rimen las líneas, sino que también entienda el contexto global, es decir, que pueda entender el poema al completo y un poco de qué va el poema y que no se ponga a mezclar tópicos. Entonces, antes de que veáis el resultado final y cómo escribe poemas, os quería hablar un poco del problema de algunos los problemas que veo con el paper. El primero de todos es con la definición que tienen ellos de innovación, que es un paper alucinante, ¿vale? Me cambia muchísimo las cosas, pero creo que hay un problema, por ejemplo, a la hora de definir innovación. Si os fijáis aquí cuando están discutiendo los trabajos anteriores sobre neural architecture research, que es básicamente muy similar a lo que está haciendo el sistema que han creado en este paper, pues ellos dicen que trabajos previos se limitaban a explorar espacios solo definidos por humanos y esto lo llaman a optimización automatizada y ellos dicen que ya no están en eso y que se han metido en innovación, ¿vale? Dicen innovación automatizada. Yo tengo un problema con eso porque no sé por qué ellos no ven el experimento, al menos que han seguido como optimización también porque realmente ellos han cogido una arquitectura que había sido creada, perdonad que no encuentro la página aquí, por humanos, que es la Deltanet, y han ido optimizando de una manera evolutiva arquitecturas e iterando sobre la Deltanet hasta que han conseguido arquitecturas state of the art, pero ellos lo que han hecho no ha sido una innovación desde cero. Ellos lo que han hecho ha sido optimizar una arquitectura creada por humanos existente y además basándose, como nos habíamos fijado antes, en papers que incluyen conocimiento humano preexistente. Entonces, ¿es esto innovación? Por eso creo aquí que es donde deberían de haber definido los dos tipos diferentes de innovación que hay. Y para ilustrar los dos tipos de innovación reales que hay, que no han mencionado, os voy a mostrar aquí las islas Galápago. Y es que el primer tipo de innovación, que es el que yo creo que ellos han realizado, que lo podemos ver aquí especialmente en este árbol evolutivo, pues es un tipo de innovación que consiste en algo preexistente y optimizarlo. Es como si vosotros llegarais a las islas Galápago y dijerais, "Vale, yo conozco a la especie del pintón. Vamos ahora a mapear todo el árbol genealógico de los pinzones y hacer descubrimientos dentro de la rama del pinzón. estaríais optimizando básicamente una isla de innovación, por así decirlo. Y lo que han hecho estos investigadores sería como en vez de hacer como que eres un explorador individual, eres un Darwin, pues tú en vez de ir pinzón por pinzón de una manera lenta, pues ellos han construido un dron que se explora la isla entera y te mapea a todos los pinzones que hay automáticamente con además la ventaja que aquí sí que mola un montón de que pues sí que ha podido innovar con ciertos conceptos, al menos mezclando ciertos conceptos que esto lo han comparado con el movimiento número 37 de Alfa Go, que si no lo habéis visto es alucinante. Es uno de los momentos históricos del campo de la donde un juego como el Go, que tiene una complejidad enorme, estaban enfrentando a Lisol y a Alfago y realizó un movimiento Alfa que nunca había hecho un humano y había pensado, "Vale, esto tiene todo el sentido y lo había realizado en el campeonato y si os fijáis, por ejemplo, Lisedol la reacción que tuvo fue irse. se fue del tablero y luego también los los presentadores, si os fijáis, estaban como no entendían el movimiento. Si os fijáis, se realizó el movimiento y ellos estaban como mirando la pantalla confundidos y pensando que era un error, pero no era porque había descubierto algo que no había descubierto antes un humano. Pues esto es igual, es con Alfago. Están optimizando todos los movimientos posibles dentro de la isla del Álfago y aquí están optimizando todo lo posible dentro de la isla Deltanet. Están descubriendo todos los pinzones que hay en Deltanet, pero ellos dicen que esto es automated innovation. A mí me hubiera gustado que hubieran mencionado que sí es innovación, pero es este tipo de innovación número uno, porque ya un tipo de innovación número dos, pues sería algo como irse a una isla diferente y en vez de descubrir el pinzón como explorador descubrir una especie nueva completamente diferente, nada relacionada al pinzón ni a las especies de las que viene el pinzón, algo como descubrir la penicilina desde cero o el transformer desde cero, que Eso es el segundo tipo de innovación, que es verdaderamente la innovación que más rompe los paradigmas. Entonces, me hubiese gustado que hubiesen hecho esa definición de innovación porque es un término tan abstracto que se usa muy a la ligera a veces. Y el segundo problema que tengo, que no es solo con este paper, sino en general con la definición y cómo se suelen dar los nombres en la comunidad de la es que no me gusta el término de superinteligencia. Y voy a explicar por qué. Algunos que ya me conocéis sabéis que yo he escrito un paper que es empirista en el que hablo de o trato, al menos de, como yo veo las cosas, de identificar dónde se origina la lógica y que hace que cuando escuchamos algo lógico, pues que lo identifiquemos como correcto. Y básicamente luego intento enseñarle la lógica a un modelo de IA. Y el resumen es que es la realidad en la que vivimos la que origina los axiomas de la lógica. ya es especialmente gracias a que existe en nuestras cabezas el concepto de objeto, el concepto de unidad que los sacamos todos de la realidad en la que vivimos, que bueno, esa es mi opinión y lo que he intentado argumentar en este paper eh que publiqué. Entonces, ¿por qué no me gusta el término de superinteligencia artificial y que lo pongan así de esta manera en la que dicen que explota la inteligencia? Pues porque debo de remarcar esta frase que dio Alberinstein una vez que dice que el genio es 1% de talento y un 99% de trabajo duro. Entonces, si la lógica se origina de la realidad y ese es el axioma lógico en base al cual hacemos descubrimientos y luego todos estos descubrimientos de nuevas arquitecturas, si lo descompones en pasos, pues en realidad es un proceso que simplemente seera continuamente ya escoger una idea, iterarla, combinarla con otras ideas. Pues al menos como yo estoy viendo las cosas más que ser un genio, lo que requiere es de un montón de trabajo. Y es por eso que creo que Albert Einstein se refería al genio como 99% de trabajo duro en vez de talento puro. Entonces, creo que esta gráfica es cierta. Creo que llegará un punto en el que tendremos una arquitectura que producirá un montón de descubrimientos y superrápido, pero no creo que será porque tenga superideas un talento del 99%. Yo creo que será porque podrá trabajar superrápido, podrá plantear nuevas ideas superrápido, podrá probar esas ideas super rápido, analizarlas, compararla con ideas previas, construir sobre pensamiento de First principles, como se llama, y es con todo ese trabajo acumulado que podrá realizar esos descubrimientos. Probablemente me he explicado superm, pero es por eso que creo que no debería de llamarse inteligencia superinteligencia artificial, sino me gusta más el término artificial super worker y que cuando se acelere todo ese proceso de iteración y de descubrimiento científico y prueba y error y volver a iterar y continuar aprendiendo, pues creo que verdaderamente van a explotar los descubrimientos. Pero bueno, esa es solo mi opinión, no es ninguna verdad, ¿vale? Y bueno, el modelo parece que ha terminado de entrenarse. Estoy grabando esto unas horas más tarde, han pasado cuatro epx, ha estado entrenándose. Debo de decir que este dataset es un poco difícil porque usa mucha terminología difícil, muchas analogías, así que no he conseguido una los muy baja, es decir, un modelo que haga que pueda predecir muy bien el próximo token, por así decirlo, pero eh todo esto está bifcodeado la mayoría. Pero bueno, al final conseguido que si por ejemplo pongo una casa, pues me está generando poemas como estos. Una casa va dando a su voz y a la vida, se ha muerto o vino ave no tiene mucho sentido. Es un modelo creo que de 12 millones de parámetros, no se ha entrenado con muchos datos, así que tampoco estaba esperando demasiado. Me dice, "¿Y en la historia de la vida, un beso a una y un día?" Bueno, esto la mayoría, como digo, vacodeado, solo que he tenido que entrar aquí en la en una de las funciones que ellos proporcionaban el código. Y si vais a entrenar a un modelo también y perdón, fijaros en que no tengan un punto ítem, porque esto me estaba dando problemas con el compilador a la hora de entrenar y estaba ralentizando muchísimo el entrenamiento, así que aquí sí que he tenido que entrar y echarlo un vistazo, pero la verdad, bueno, probablemente suba el modelo también en el caso de que lo queráis probar y generar un poco de poesía, puedo poner otro ejemplo como las rosas. Vamos a ver qué nos genera. Y bueno, también he tenido algún problema con el formato, así que lo que he hecho ha sido simplemente conseguir el output del modelo que tengo entrenado. Y luego se lo he pasado a Gemini para que le dé la estructura de un poema porque no estaba haciendo bien los saltos de línea, pero bueno, ha sido un pequeño parche que he implementado y me dice, "Las rosas y como nadie hay que soy mi corazón, me da la mañana y la luna hasta que en el deseo me ha la luz y en el desierto y el que es tu nombre que te quiero." Así que bueno, eh parece bastante similar a lo que generalmente suele haber por aquí, así que bastante guay. Pero bueno, eso sería en general un poco la review de la nueva superinteligencia artificial para la investigación. Esto es definitivamente un gran paso hacia delante en cuanto se pueda automatizar completamente y conseguir una innovación de tipo dos. Con arquitecturas como estas, yo creo que va a ser cuando verdaderamente veremos esa explosión en nuevos descubrimientos. Pero nada, si os interesa continuar viendo papers como estos, suscribiros al canal y bueno, un saludo a todos y paz.

---

Modelo: mistral:latest
Fecha: 2025-08-01 20:40:48
URL: https://youtu.be/83UujN1Fmus
Video ID: 83UujN1Fmus